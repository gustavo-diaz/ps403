---
title: "Lab 6: Dealing with Missing Data"
author: 
  - FirstName LastName
  - <YourEmail@u.northwestern.edu>
date: November 11, 2024
date-format: "**[D]ue:** MMMM D, YYYY"
format: 
     pdf:
       documentclass: article
fontsize: 12pt
urlcolor: blue
number-sections: true
geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in
header-includes:
    - \usepackage{setspace}
    - \doublespacing
---

```{r setup, include=FALSE}
# Code chunk options
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      tidy = FALSE,
                      tidy.opts=list(width.cutoff=80))

# Packages
library(tidyverse)
library(estimatr) # Regression with robust standard errors
library(tinytable) # Print pdf tables
library(haven) # Read .dta files
library(car) # Data for the lab
```

# Missing not at random

This week, we learned about two assumptions that one could make to conduct *valid* statistical inference with missing data, MCAR and MAR. These are both restrictive assumptions, and in most applied setting we can only justify observations Missing Not At Random (MNAR)^[Sometimes also called Not Missing at Random (NMAR). MNAR and NMAR mean the same, but one or the other may make more sense depending on your preferences English grammar preferences.] MNAR implies that data are missing in a way that depends on unobserved covariates, so we cannot simply adjust or impute based on the data we have collected.

Still, we make assumptions not because they are true, but because they are useful. From that point of view, you want to show that whatever you assume is not particularly harmful for the inferences you draw.

To illustrate this point, consider the study by [Dettman, Pepinsky and Pierskalla (2017)](https://doi.org/10.1016/j.electstud.2017.06.002) on incumbency advantage in Indonesia's 2014 legislative elections.

To beging, we will load the data.

```{r, results = "hide"}
url = "http://gustavodiaz.org/ps403/data/dpp_replicate.dta"

dpp = read_dta(url)

# inspect but do not print
dpp
```

The original data already has some missing observations, but we will pretend that it does not for the sake of illustration. This drops about 600 observations from the 6600 total.

```{r, results = "hide"}
# drop nas
dpp = dpp %>% drop_na

# inspect but do not print
dpp
```

We will then reproduce their main finding, which is the effect of being an incumbent on their vote share. Including a bunch of covariates (the `type_*` variables are indicators for different kinds of candidate occupations). We are also including fixed effects for electoral districts and clustering our standard errors by electoral district as well.^[You will learn what fixed effects and clustered standard errors are next term.]

```{r}
specification = formula(
"pct_suara ~ incumbency +
female + age + factor(religion_new) +
factor(party) + education +
type_1 + type_2 + type_3 + type_5 + type_6 + type_7 +
type_9 + type_10 + type_11 + type_12 + type_13 +
type_14 + type_15 + type_16 + type_17 + type_18 + 
type_19 + type_21"
)

lm_original = lm_robust(
  formula = specification,
  data = dpp,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata" # too slow otherwise
)

# We only need to look at the effect of incumbency
original = tidy(lm_original) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Original") %>% 
  select(procedure, term, estimate, std.error)

original
```

Let's pretend this is our "ground truth."^[This is exactly the same as the result presented in Column 1 of Table 3 in the original paper. Exact reproducibility is rarely this easy.] We can induce non-ignorable missingness by randomly selecting 25% of the observations and assign the vote share outcome `pct_suara` to missing if the candidate's vote is in the highest quartile.

```{r}
# Set the seed!
dpp$miss_vote = rbinom(nrow(dpp), 1, 0.25)

dpp$high_vote = dpp$pct_suara > quantile(dpp$pct_suara, 0.75)

dpp_missing = dpp %>% 
  mutate(drop = ifelse(miss_vote == 1 & high_vote,
                       1, 0))
```


We can check the consequences of inducing missing data by estimating the effect of `incumbency` on the resulting `dpp_missing` data frame, which is equivalent to the default *listwise deletion* in `lm` and `lm_robust`. This is what most people would do by default if they are not particularly troubled by missing data. This would only yield valid estimates if we assume MCAR, but people rarely invoke this assumptions explicitly when letting software just drop missing observations.

```{r}
lm_listwise = lm_robust(
  formula = specification,
  data = dpp_missing %>% filter(drop == 0),
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata" # too slow otherwise
)

listwise = tidy(lm_listwise) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Listwise deletion") %>% 
  select(procedure, term, estimate, std.error)

listwise
```

A more principled approach would be to assume that the effect of `incumbency` is *bounded*. We can estimate lower and upper bounds by replacing our would be missing observations with the minimum and maximum values of our would be observed observations.

```{r}
range = dpp_missing %>% 
  filter(drop == 0) %>% 
  summarize(min_vote = min(pct_suara),
            max_vote = max(pct_suara))

dpp_bound_low = dpp %>% 
    mutate(pct_suara = ifelse(miss_vote == 1 & high_vote,
                       range$min_vote, pct_suara))

dpp_bound_high = dpp %>% 
    mutate(pct_suara = ifelse(miss_vote == 1 & high_vote,
                       range$max_vote, pct_suara))


lm_bound_low = lm_robust(
  formula = specification,
  data = dpp_bound_low,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata"
)

lm_bound_high = lm_robust(
  formula = specification,
  data = dpp_bound_high,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata"
)

bound_low = tidy(lm_bound_low) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Lower bound") %>% 
  select(procedure, term, estimate, std.error)

bound_high = tidy(lm_bound_high) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Upper bound") %>% 
  select(procedure, term, estimate, std.error)

# Visualize together
bind_rows(bound_low, bound_high)
```


If we explicitly assume MCAR, we can impute the mean value of the observed sample into missing outcomes. This is referred to as *mean imputation* for short.

```{r}
# Calculate avg vote share if not missing
mean_vote_missing = dpp_missing %>%
  filter(drop == 0) %>% 
  summarize(avg_vote = mean(pct_suara)) %>% 
  .$avg_vote # This last part returns the number as a vector

# Impute sample average if missing
dpp_mcar = dpp %>% 
  mutate(pct_suara = ifelse(miss_vote == 1 & high_vote,
                       mean_vote_missing, pct_suara))

# Estimate
lm_mcar = lm_robust(
  formula = specification,
  data = dpp_mcar,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata"
)

mcar = tidy(lm_mcar) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "MCAR imputation") %>% 
  select(procedure, term, estimate, std.error)

mcar
```

We can also consider what two options that become viable if we assume MAR. First, we can impute missing values based on the predictions of a regression model, then estimate.



```{r}
# Update specification to fit lm object
outcome_spec = update(specification,
                      ~ . + as.factor(id_dapil))

outcome_model = lm(outcome_spec,
                   data = dpp_missing %>% 
                     filter(drop == 0))

# Draw predictions in the whole data set
dpp$reg_pred = predict(outcome_model, newdata = dpp)

# Impute data
dpp_reg = dpp %>% 
  mutate(pct_suara = ifelse(miss_vote == 1 & high_vote,
                       reg_pred, pct_suara))

# Estimate
lm_reg = lm_robust(
  formula = specification,
  data = dpp_reg,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata"
)

regression = tidy(lm_reg) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Regression imputation") %>% 
  select(procedure, term, estimate, std.error)

regression
```

Which, incidentally, is the same as just replacing the every observation with its prediction, although with nonsensical standard errors.

```{r}
specification2 = update(specification,
                        reg_pred ~ .) 

lm_reg2 = lm_robust(
  formula = specification2,
  data = dpp,
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata"
)

tidy(lm_reg2) %>% 
  filter(term == "incumbency") %>% 
  select(term, estimate, std.error)
```

The alternative under MCAR is to estimate a propensity score, and then use inverse probability weighting (IPW) to adjust results. Our preferred specification already include a regression specification with covariates, so a "pure" IPW estimation doesn't make much sense. Instead, the code belows adds IPW to the existing regression specification, which equivalent to performing *doubly robust estimation*.

```{r}
# Estimate propensity score
pscore_spec = update(specification,
                     (1-drop) ~ .)

pscore_model = glm(pscore_spec,
                   data = dpp_missing,
                   family = binomial)

# Predict on entire data set
pscore = predict(pscore_model, type = "response")

# Create ipw
dpp_missing$ipw = 1/pscore

# Estimate
lm_dr = lm_robust(
  formula = specification,
  data = dpp_missing %>% filter(drop == 0),
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata",
  weights = ipw
)

dr = tidy(lm_dr) %>% 
  filter(term == "incumbency") %>% 
  mutate(procedure = "Doubly robust") %>% 
  select(procedure, term, estimate, std.error)

dr  
```

Passing the `weights` argument turns the estimation into *weighted least squares*, the closes analog to HÃ¡jek's stabilized IPW for the multivariate regression context. See [this note](https://declaredesign.org/r/estimatr/articles/mathematical-notes.html#lm_robust-notes) for details.

Just for your reference, this is how you would perform ipw adjustment on its own in the regression context with the `estimatr` package.

```{r}
lm_robust(
  formula = pct_suara ~ incumbency,
  data = dpp_missing %>% filter(drop == 0),
  fixed_effects = ~id_dapil,
  clusters = id_dapil,
  se_type = "stata",
  weights = ipw
) %>% 
  tidy() %>% 
  select(term, estimate, std.error)
```

Finally, we can use `tidytable` to combine visualize all these results at the same time (try to make the table look prettier if you can).

```{r}
results = bind_rows(
  original,
  listwise,
  bound_low,
  bound_high,
  mcar,
  regression,
  dr
)

results %>% tt()
```


## Conceptually, what do MCAR and MAR mean? How are they different? When is one more appropriate than the other?

## Interpret the results of each procedure. How well do they approximate the original results? Are they worth the additional assumptions?

## Add additional columns to the table with 95% confidence intervals for each procedure. In terms of statistical inference, how do our overall conclusions change with each procedure?

## Generally speaking, what is your preferred procedure? Explain

# Multiple imputation

<!-- Listwise deletion -->

<!-- mice -->

<!-- amelia -->