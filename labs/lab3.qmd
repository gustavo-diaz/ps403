---
title: "Lab 3: Estimation"
author: 
  - FirstName LastName
  - <YourEmail@u.northwestern.edu>
date: October 13, 2025
date-format: "**[D]ue:** MMMM D, YYYY"
format: 
     pdf:
       documentclass: article
fontsize: 12pt
urlcolor: blue
number-sections: true
geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in
header-includes:
    - \usepackage{setspace}
    - \doublespacing
    - \usepackage{float}
    - \floatplacement{figure}{h}
    - \floatplacement{table}{h}
    - \usepackage{flafter}
    - \usepackage[utf8]{inputenc}
    - \usepackage{ragged2e}
    - \usepackage{booktabs}
    - \usepackage{amsmath}
    - \usepackage{url}
    - \usepackage{fvextra}
    - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
# Global options for the rendering behavior of all subsequent code chunks
# Set tidy = TRUE if code overflows
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      tidy = FALSE) 

# Packages, add more here as needed
library(tidyverse)
library(tinytable)
library(mosaic) # easy resampling

# Set your own seed with something like your Wildcard ID number
seed = 1234
```

# Overview {.unnumbered}

The purpose of this lab is to learn and write about the statistical properties of various estimators.

## Data {.unnumbered}

For this lab, we will work with data from the General Social Survey (GSS). The R package [`{gssr}`](https://kjhealy.github.io/gssr/index.html) helps us load the data. However, this package is too big to host in CRAN (the official R repository), so we need to install the package from GitHub.^[There is a companion package that lists all the variables included: <https://kjhealy.github.io/gssrdoc/>. You can technically install this too, but I recommend you just browse the website.]

```{r}
## You may need to run the two commented lines the first time

# install.packages("remotes")

# remotes::install_github("kjhealy/gssr")
library(gssr)
```

The package has data for the 1972-2022 period. We will focus on the most recent survey. For demonstration, I will focus on whether the respondent recalls having voted in the 2020 election (`vote20`).

The following code selects the variable and recodes it as a binary indicator.

```{r, results="hide"}
gss22 = gss_get_yr(2022)

gss = gss22 %>% 
  select(vote20) %>% 
  mutate(vote = ifelse(vote20 == 1, 1, 0)) %>% 
  drop_na()

gss # This will print in RStudio but not on the PDF
```

Notice that we are dropping missing observations. For now, we will pretend this is not a big deal. On Week 9, we will discuss when and how missing data is a problem, and what to do about it.

You can learn more about the GSS [here](https://gss.norc.org/content/dam/gss/get-documentation/pdf/codebook/GSS%202022%20Codebook.pdf).

## Diagnosing statistical properties {.unnumbered}

For the purposes of the lab, we will pretend that the entire data set is a population. That way, we can "know" the true population quantity of interest.

Let's say we are interested in the proportion of people who remember voting in the 2022 election.

```{r}
vote_pop = mean(gss$vote)

vote_pop
```

We then want to simulate a study that randomly samples one hundred individuals from the population (withour replacement since this is a realistic example) and then calculates the mean response.

```{r}
set.seed(seed)

x = sample(gss$vote, size = 100, replace = FALSE)

mean(x)
```

How close is this to the true proportion? We cannot know without repeating the process multiple times.

For that, we need a function that automates drawing a sample of size `n` and calculating the mean

```{r}
sample_mean = function(data, n){
  data %>% 
    sample_n(size = n) %>% 
    summarize(
      mean = mean(vote)
    )
}

# Apply to see if it works
sample_mean(gss, 100)
```

We then need to repeat the process multiple times to simulate many independent studies. The easiest way to do this is with the `do()` function in the mosaic package.

```{r, results="hide"}
# number of studies
reps = 1000

set.seed(seed)
vote_df = do(reps) * sample_mean(gss, 100)

# check output
vote_df
```

This is often referred to as a (re)sampling distribution. We can then visualize it in `{ggplot2}`. 

```{r}
ggplot(vote_df) +
  aes(x = mean) +
  geom_density() +
  geom_vline(xintercept = vote_pop,
             linetype = "dashed",
             color = "purple")
```

We can then use this figure to talk about some of the statistical properties of this estimator. 

Because we are pretending that we know the population, we can also quantify bias and efficiency (measured as mean squared error, MSE)

```{r}
vote_df %>% 
  summarize(
    bias = mean(mean - vote_pop),
    mse = mean((mean - vote_pop)^2)
  ) %>% 
  tt()
```


{{< pagebreak >}}

# New variable

Look at the [`{gssr}` documentation](https://kjhealy.github.io/gssrdoc/reference/index.html), then choose a variable that interests you.

Explain what the variable contains, why you chose it, and how it is coded. Recode it as numerical or binary if necessary so that we can apply some estimators. If you recode it, explain the logic behind it.

# Sample mean again

Diagnose the statistical properties for the sample mean for this variable. Make a well formatted figure(s) or table(s) similar to those presented above. Remember that if you show a figure or table, you need to write about it.


**Questions:**

1.  *How do the statistical properties of the sample mean of your new variable compare to the properties of the mean of `vote`? Explain*
2. *What would be the ideal sample size to ensure the sample mean for the new variablehas good statistical properties? Show at least three options and explain. You will commit to this sample size for the remainder of the lab*

# Sample variance

Using the new variable you selected, diagnose the statistical properties of the following two candidates for an estimator of the sample variance (these are the same we discussed in class).

$$
\textbf{Option 1: }\widehat V^*[X] = \overline{X^2}-\overline{X}^2
$$

$$
\textbf{Option 2: }\widehat V[X] = \frac{n}{n-1}(\overline{X^2}-\overline{X}^2)
$$

Option 2 is just the `var` function in base R. For option 1, we may need to create a custom function. It may be a good idea to work together to make sure everyone is using the right function.


**Questions**

1. *Which estimator of the sample variance has better statistical properties? Explain*

2. *In general terms, why do we need a bias-corrected estimator for the sample variance? Is there a case in which we do not need it?*

3. *Generally speaking, when is an estimator of the sample variance useful or important? Think about a case in which you would prefer to report the sample variance (or standard deviation) over the sample mean.*


# Your own estimator

Repeat the process above for at least one new estimator of your choosing. This would be a decent approximation of the process of learning about a new method. You may select from the following list:

- Sample median
- Sample mode
- Sample quantile or percentile (e.g. 0.2, 0.95)
- The covariance or correlation between two variables (which would need picking a second  variable)
- The rank correlation between two variables (remember there is two)
- Truncated or trimmed mean
- Winsorized mean
- The difference in means between two groups in the data (e.g. by binary sex, democrat vs. republican supporters, white vs. others)
- The ratio of the variance between two groups, or between two variables (this is usually called an F-test or F-statistic)
- The $\Beta$ coefficient in OLS regression (bivariate or multivariate)
- The $\Beta$ coefficient in logistic regression (bivariate or multivariate)

Or pick another estimator that you may want to learn about. In either case, the expectation is that you would include appropriate references.

**Questions:**

1. *In theory, why would someone want to use this estimator? Describe a scenario relevant to your subfield or discipline*
2. *What is the target estimand? What do we need to assume to believe the estimator produces a reasonable approximation of the estimand? Pay special attention to required assumptions beyond i.i.d. sampling*
3. *Explain how this estimator is applied to data (e.g. the mean is the sum of all values divided by the numbers of observations) and how one should implement it in R*
4. *Use the strategies from previous sections of this lab to diagnose the estimator (remember to walk the reader through the process)*
5. *Based on the variable(s) you chose, would you recommend using this estimator?*

     - *If no, under what circumstances would you recommend using this estimator (e.g. larger sample size, different kind of variables)?*
     - *If yes, when do you think the estimator will perform poorly?*
     
&nbsp; &nbsp; *For this last question, you do not need to show new code or results.*