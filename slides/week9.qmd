---
format: 
  revealjs:
    slide-number: false
    progress: false
    chalkboard: true
    code-overflow: wrap
    code-line-numbers: false
---


```{r setup, include=FALSE}
# Global options for the rendering behavior of all subsequent code chunks
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE,
                      message = FALSE,
                      fig.pos = "center")

library(tidyverse)
library(tinytable)
library(kableExtra) # too lazy to change
library(DeclareDesign) # Re-randomize
library(infer)

# tinytable options
# options(tinytable_html_mathjax = TRUE)
```


## Return to strong ignorability

We can still conduct valid causal inference if we believe treatment assignment is **strongly ignorable** (conditional on covariates)

Requirements:

- *Conditional independence*: $(Y_i(0), Y_i(1)) \perp \!\!\! \perp D_i | \mathbf{X}_i$
- *Positivity*: There exists $\epsilon > 0$ such that $$\epsilon < Pr[D_i = 1 | \mathbf{X}_i] < 1 - \epsilon$$

. . .

::: {.r-stack}
What if we could guarantee strong ignorability *by design*?
:::

## Quasi-experiments

::: incremental
- *Observational* studies
- Data structured such that we can credibly make causal claims
- We can *treat* them as experiments but they **are not**
:::

. . .

Examples:

1. Regression discontinuity design (RDD)

2. Difference-in-differences (DID)

## RDD ingredients

::: incremental
- $Y_i$: outcome

- $X_i$: score or running variable

- $c$: cutoff or threshold

- $T_i$: Treatment indicator
:::

. . .

**Potential outcomes**

$$
Y_i = (1 - T_i) Y_i(0) + T_i Y_i(1) = \begin{cases}
Y_i(0) & \text{if } X_i < c\\
Y_i(1) & \text{if } X_i \geq c
\end{cases}
$$

## Sharp RDD

![](fig/rd_assign.png){fig-align="center" width=59%}

::: aside
Called *sharp* because treatment assignment is *deterministic* on the cutoff
:::

## Interpretation: Two approaches

:::: {.columns}

::: {.column width="60%"}

![](fig/rd_assign.png)

:::

::: {.column width="40%"}


1. Local randomization

2. Continuity-based


:::
::::

## Local randomization approach

:::: {.columns}
::: {.column width="60%"}
![](fig/rd_rand.png)
:::

::: {.column width="40%"}
::: incremental
- Bandwidth $\mathcal{W} = [câˆ’w,c+w]$

- Treatment **as-if** random within $\mathcal{W}$

- ATE *point-identified* within $\mathcal{W}$

:::

:::

::::


## Local randomization approach

:::: {.columns}
::: {.column width="60%"}
![](fig/rd_rand.png)
:::

::: {.column width="40%"}

**Requirements**

::: incremental
1. Known probability distribution of scores within $\mathcal{W}$ ($\equiv$ random assignment)

2. Potential outcomes **not affected by scores** within $\mathcal{W}$

:::

:::

::::

## Local randomization approach

:::: {.columns}
::: {.column width="60%"}
![](fig/rd_rand.png)
:::

::: {.column width="40%"}

**Estimation**

::: incremental
- Difference in means within $\mathcal{W}$
:::

**Inference**

::: incremental

1. Randomization inference

2. Normal-approximation (*super-population*)

:::

:::

::::

## Continuity-based approach

:::: {.columns}
::: {.column width="60%"}
![](fig/rd_cont.png)
:::

::: {.column width="40%"}
::: incremental
- ATE is *point-identified* at cutoff

- $\tau_{SRD} \equiv E[Y_i(1) - Y_i(0) | X_i = c]$

- But it does not exist!

- Still, we can approximate

:::

:::

::::

## Continuity-based approach

:::: {.columns}
::: {.column width="60%"}
![](fig/rd_cont.png)
:::

::: {.column width="40%"}

- ATE is *point-identified* at cutoff

- $\tau_{SRD} \equiv E[Y_i(1) - Y_i(0) | X_i = c]$

- But it does not exist!

- Still, we can approximate

$$
\begin{align}
&\tau_{SRD} = \\
& \lim_{x \downarrow c} E[Y_i | X_i = x] -
\lim_{x \uparrow c} E[Y_i | X_i x]
\end{align}
$$
:::

::::

## Local polynomial point estimation

**Steps**

::: incremental
1. Choose polynomial $p$ and kernel function $K(\cdot)$

2. Choose bandwidth $h$

3. Fit $\widehat \mu_+$ and $\widehat \mu_-$ via *weighted least-squares* (based on $K(\cdot)$)

4. Estimate: $\widehat \tau_{SRD} = \widehat \mu_+ - \widehat \mu_-$

5. Inference: Correct for adaptive bandwidth selection
:::

::: aside
This a non-parametric procedure since most choices are automated to find optimal MSE
:::

## Polynomial $p$

::: aside
Different polynomials yield different estimates
:::

![](fig/rdd_poly.png){fig-align="center" width=90%}

## Kernel function $K(\cdot)$

![](fig/rd_kernel.png){fig-align="center" width=60%}

::: aside
$K(\cdot)$ assigns weights to units based on distance to cutoff (triangular performs better)
:::

## Bandwidth $h$

::: aside
**Narrower:** less bias, more variance. 
**Wider:** more bias, less variance 
:::

![](fig/rdd_bw2.png){fig-align="center" width=90%}

## DID ingredients

